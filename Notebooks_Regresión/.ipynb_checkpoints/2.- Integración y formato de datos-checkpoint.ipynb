{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "<div class=\"jumbotron\">\n",
    "  <h1><i class=\"fa fa-bar-chart\" aria-hidden=\"true\"></i> Integracción y limpieza</h1>\n",
    "  <p></p>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Objetivo\n",
    "\n",
    "Integrar todas las fuentes de datos en un único archivo con formato PICKLE, el cual será utilizado en los pasos de análisis. El archivo se almacena en el folder `data/interim/`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pandas import read_csv,set_option\n",
    "import  pickle\n",
    "import numpy as np\n",
    "import glob\n",
    "import os\n",
    "import urllib.request\n",
    "from os import path\n",
    "from dotenv import load_dotenv, find_dotenv\n",
    "\n",
    "os.chdir(\"..\")\n",
    "set_option('display.width', 1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Obtención de los datos "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Download"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lista de URs de los meses que se analizan \n",
    "urls = ['','','']\n",
    "\n",
    "# Download\n",
    "for url in urls :\n",
    "    filename = url.split('/')[-1]\n",
    "    path_file = '../data/raw/' + filename\n",
    "    if not path.exists(path_file):\n",
    "        urllib.request.urlretrieve(url, path_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fuentes y diccionario de datos\n",
    "\n",
    "### Sobre los datos\n",
    "\n",
    "### Diccionario de datos\n",
    "\n",
    "### ¿Qué transformaciones ha sufrido el archivo?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cargar datos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cargar todos los archivos con un misma estructura"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "path = os.getcwd()\n",
    "all_files = glob.glob(os.path.join(path , \"../data/raw/*.*\"))\n",
    "\n",
    "#lista de dataframes\n",
    "li = []\n",
    "\n",
    "for filename in all_files:\n",
    "    df = read_csv(filename, index_col=None, header=0)\n",
    "    \n",
    "    li.append(df)\n",
    "\n",
    "# df = pd.concat(li, axis=0, ignore_index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Carga individual"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df = read_csv('', error_bad_lines=False) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Descripción "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mostrar los 5 primeros renglones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mostart las dimensiones del `Dataframe` "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-info\" role=\"alert\">\n",
    "<ul>\n",
    "<li> insights ... </ul>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Nombre de las columnas "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cambiar el nombre de las variables\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# columns = []\n",
    "# df.columns = columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tipo de datos detectados por Pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dar formato de datetime a las variables de tiempo y fechas "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Formatos de fecha comunes\n",
    "format= '%Y-%m-%d %H:%M:%S'\n",
    "format_alternativo = '%m/%d/%Y %H:%M:%S'\n",
    "    \n",
    "# Catch string to datetime\n",
    "# df['datetime'] = pd.to_datetime(df[''],format=formato)\n",
    "\n",
    "\n",
    "# Filtro para conversión\n",
    "# df[''] = df[''].str.replace('\\..*', '')\n",
    "\n",
    "# df[''] = df[''].apply(lambda x: len(x))\n",
    "\n",
    "\n",
    "# Extraer periodo de tiempo\n",
    "# df['periodo'] = df.__.apply(lambda x: x.strftime('%Y-%m'))\n",
    "\n",
    "# Extracción de partes de la fecha\n",
    "# df_movie['year']=df_movie[''].dt.year\n",
    "# df_movie['month']=df_movie[''].dt.month\n",
    "# df_movie['day']=df_movie[''].dt.day"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Estandarizar fecha"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.datime_format import datetime_convert\n",
    "\n",
    "# format = '%Y-%m-%d %H:%M:%S'\n",
    "\n",
    "# df.__.apply(lambda x: datetime_convert(x,output_format= format))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Valores nulos o faltantes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Valores nulos como porcentaje "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "((df.isnull().sum() / len(df))*100).sort_values(ascending = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-info\" role=\"alert\">\n",
    "<ul>\n",
    "<li> En términos generales, se suelen considerar los siguientes grados de impacto, dependiendo del porcentaje de valores faltantes (dumb rules):\n",
    "\n",
    "- Menos de 1%: Trivial (no relevante)\n",
    "- 1-5%: Manejable\n",
    "- 5-15%: Manejable mediante métodos sofisticados\n",
    "- Más de 15%: Crítico, con impacto severo en cualquier tipo de interpretación\n",
    " \n",
    "    \n",
    "Debido a que la mayoría de la variables contiene datos ausentes con un porcentaje inferior al 1% se procederá a remover dichas muestras. La variables 'Genero_Usuario' al no rebasar el 5% de datos ausentes puede continuar dentro de las variables de análisis sin un mayor impacto que remover la muetras que contienen valores nulos.\n",
    "    \n",
    "<li> Nota: Por falta de tiempo no se lidia con los datos faltantes de la variable Genero_Usuario. En un entorno productivo si la varible sobre pasa en 1% se debe utilizar tecnicas de inputación de datos para reducir el porcentaje de valores nullos.\n",
    "    \n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analisis de valores faltantes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Inputación de valores faltantes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Se eliminan\n",
    "df.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Número de muestras eliminados\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Valores duplicados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remover los datos duplicados\n",
    "# df.drop_duplicates(keep='first',inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Núm. de registros eliminados"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Verificar datos "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Datos nulos\n",
    "((df.isnull().sum() / len(df))*100).sort_values(ascending = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Obtener el nombre de las variables categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# categorical = []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convertir las variables a tipo `category`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for name in categorical :\n",
    "#    df['']= df[''].astype(\"category\")#.cat.codes.values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Almacenar el `dataframe` en formato pickle "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Store data en formar pickle\n",
    "with open('../data/interim/format.pickle', 'wb') as handle:\n",
    "    pickle.dump(df, handle)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
