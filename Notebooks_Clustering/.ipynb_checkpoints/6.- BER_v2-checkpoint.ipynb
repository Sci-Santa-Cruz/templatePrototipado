{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "<div class=\"jumbotron\">\n",
    "  <h1><i class=\"fa fa-bar-chart\" aria-hidden=\"true\"></i> Modelado de datos</h1>\n",
    "  <p></p>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import clear_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1.02 s, sys: 123 ms, total: 1.14 s\n",
      "Wall time: 49.1 s\n"
     ]
    }
   ],
   "source": [
    "\n",
    "%%time\n",
    "! pip install pip --upgrade\n",
    "! pip install pyopenssl --upgrade\n",
    "! pip install nltk \n",
    "! pip install mlflow\n",
    "! pip install transformers==4.28.1\n",
    "! pip install sentence_transformers\n",
    "! pip install nanoid==2.0.0\n",
    "! pip install pandas\n",
    "! pip install imblearn\n",
    "! pip install scikit-learn --upgrade\n",
    "! pip install accelerate\n",
    "! pip install imbalanced-learn\n",
    "! pip install ipywidgets\n",
    "! pip install jupyterlab-widgets\n",
    "! pip3 install torch torchvision torchaudio\n",
    "\n",
    "clear_output(wait=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# ! pip install klp_commons\n",
    "# ! pip install pymongo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import json \n",
    "from torch.utils.data import TensorDataset, DataLoader, RandomSampler, SequentialSampler\n",
    "from transformers import BertTokenizer, BertForSequenceClassification\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, precision_recall_fscore_support\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from transformers import BertTokenizer, BertForSequenceClassification\n",
    "from datetime import datetime\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tabulate import tabulate\n",
    "from tqdm import trange\n",
    "import random\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from transformers import AutoTokenizer, AutoModel\n",
    "from numpy import logspace\n",
    "from torch.nn import functional as F\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "# from klp_commons.controllers.controller_mongodb import ControllerMongoDB\n",
    "\n",
    "# Métodos MLFlow\n",
    "import mlflow\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import pickle\n",
    "from nanoid import generate\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "logger = logging.getLogger()\n",
    "logger.setLevel(logging.ERROR)\n",
    "\n",
    "os.environ[\"NODE_ENV\"] = 'production'\n",
    "os.environ[\"JWT_SECRET\"] = 'kl0pp2oZ2'\n",
    "os.environ[\"SENTRY_DSN\"] = \"https://c1f07405e41446dbbfc5fb4ec06cdd46@sentry.quo.services/31\"\n",
    "\n",
    "mongo_dict = dict()\n",
    "mongo_dict['master'] = 'mongodb://root:oYCFrNXT43@afed91810697546c995cf5da20b76558-1225051356.us-west-2.elb.amazonaws.com:27017'\n",
    "mongo_dict['uat'] = 'mongodb://root:mAJIDmRKiU@afc054aee72eb447f9061ef692088083-8043966.us-west-2.elb.amazonaws.com:27017'\n",
    "#mongo_dict['uat'] = 'mongodb://root:mAJIDmRKiU@uat-mongodb.klopp-mongodb:27017'\n",
    "mongo_dict['staging'] = 'mongodb://root:nyQ96rVSWk@a5031ba6be3384712b7fca47a8362814-671241708.us-west-2.elb.amazonaws.com:27017'\n",
    "#mongo_dict['staging'] = 'mongodb://root:nyQ96rVSWk@staging-mongodb.klopp-mongodb:27017'\n",
    "mongo_dict['dev'] = 'mongodb://root:oYCFrNXT43@a5d0f04be89e5457282c98d79303156b-630764425.us-west-2.elb.amazonaws.com:27017'\n",
    "# local\n",
    "mongo_dict['local'] = 'mongodb://user:admin@mongodb:27017/'\n",
    "# set env var\n",
    "os.environ[\"MONGODB_URL\"] = mongo_dict['dev']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "## Tenga cuidado con sklearn y pandas en el entorno de producción."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def preprocessing(input_text, tokenizer):\n",
    "    '''\n",
    "      Returns <class transformers.tokenization_utils_base.BatchEncoding> with the following fields:\n",
    "    - input_ids: list of token ids\n",
    "    - token_type_ids: list of token type ids\n",
    "    - attention_mask: list of indices (0,1) specifying which tokens should considered by the model (return_attention_mask = True).\n",
    "    '''\n",
    "    return tokenizer.encode_plus(\n",
    "                        input_text,\n",
    "                        add_special_tokens = True,\n",
    "                        max_length = 256,\n",
    "                        truncation=True,\n",
    "                        pad_to_max_length = True,\n",
    "                        return_attention_mask = True,\n",
    "                        return_tensors = 'pt'\n",
    "                   )\n",
    "\n",
    "\n",
    "def get_timestamp():\n",
    "    now = datetime.now()\n",
    "    year = '{:02d}'.format(now.year)\n",
    "    month = '{:02d}'.format(now.month)\n",
    "    day = '{:02d}'.format(now.day)\n",
    "    hour = '{:02d}'.format(now.hour)\n",
    "    minute = '{:02d}'.format(now.minute)\n",
    "    return '{}-{}-{}-{}-{}'.format(year, month, day,hour,minute)\n",
    "\n",
    "def uploadDirectory(path, key, bucket = 'model.klopp.mx'):\n",
    "        s3 = boto3.resource('s3')\n",
    "\n",
    "        for root,dirs,files in os.walk(path):\n",
    "            for file in files:\n",
    "                key_ = key + file\n",
    "                print(os.path.join(root,file) ,\" --> \",key_)\n",
    "                s3.meta.client.upload_file(os.path.join(root,file), bucket,key_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cargar datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# dataser base\n",
    "# hardcode -> migrar a featurestore\n",
    "df = pd.read_csv('dataset_klopp_v1_29_11_2022.csv')\n",
    "# catálogo base de categorías\n",
    "# cargar de postgres\n",
    "df_catalog = pd.read_csv('catalog_core.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# catch type \n",
    "df_catalog['subcategoria-code'] = df_catalog['subcategoria-code'].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# ============= procesar el columna subcategoria (etiqueta) en el dataset ===========\n",
    "# convertir tipo texto a tipo 'category'\n",
    "df['subcategory_cat'] = df['subcategory'].astype('category')\n",
    "\n",
    "# convertir tipo categoría a tipo code\n",
    "df['subcategory_cat'] = df['subcategory_cat'].cat.codes\n",
    "\n",
    "# filtrar muestras sin etiquetar\n",
    "# las muestras sin etiquetar se les asigna el valor -1\n",
    "df = df[df['subcategory_cat']!=-1]\n",
    "\n",
    "# reset index \n",
    "df.reset_index(drop=True,inplace= True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# merge dataset de entrenamiento con df del catálogo base\n",
    "# merge a nivel del nombre de la subcategoría en ambos DFs\n",
    "result = pd.merge(\n",
    "    df,\n",
    "    df_catalog,\n",
    "    left_on='subcategory',\n",
    "    right_on='name⦿es-MX_subcategory',\n",
    "    how='inner',\n",
    "    sort=False\n",
    "                )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# name_subcategory\n",
    "# name⦿en-US_subcategory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "dict_cat_to_code = result[['subcategory_cat','subcategoria-code','name_subcategory']].drop_duplicates()\n",
    "dict_cat_to_code.set_index('name_subcategory', inplace=True)\n",
    "dict_cat_to_code = dict_cat_to_code.to_dict('index')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Obtener códigos de subcategorías \n",
    "result_ = result[['subcategory_cat','name_subcategory']].drop_duplicates()\n",
    "result = result[['subcategory_cat','subcategoria-code']].drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Obtener diccionario de categorías equivalentes\n",
    "# harcode -> send to mongoDB\n",
    "dict_code_mapping = pd.Series(result['subcategoria-code'].values,index=result.subcategory_cat.values).to_dict()\n",
    "dict_code_cat = pd.Series(result_['name_subcategory'].values,index=result_['subcategory_cat'].values).to_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "with open(\"dict_cat_to_code.json\", \"w\") as outfile:\n",
    "    json.dump(dict_cat_to_code, outfile)\n",
    "    \n",
    "with open(\"dict_code_mapping.json\", \"w\") as outfile:\n",
    "    json.dump(dict_code_mapping, outfile)\n",
    "    \n",
    "with open(\"dict_code_cat.json\", \"w\") as outfile:\n",
    "    json.dump(dict_code_cat, outfile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# json_object = json.dumps(dict_cats, indent = 4) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# obtener  etiquetas\n",
    "labels =  df[['subcategory_cat']]\n",
    "\n",
    "# obtener descripción\n",
    "#'description_source',\n",
    "df = df[['clean_description']]\n",
    "\n",
    "# crear diccionario con conteo de número de muestras por clase\n",
    "# re sampling\n",
    "dict_resamble = (labels.subcategory_cat.value_counts() [labels.subcategory_cat.value_counts() <11]).to_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "hacer un resampling para las categorías que no cumplen con el número mínimo de muestras\n",
    "núm mínimo = 10 \n",
    "\n",
    "\"\"\"\n",
    "\n",
    "df_ = df[labels.subcategory_cat.apply(lambda x: x in list(dict_resamble.keys()))]\n",
    "\n",
    "df = df[labels.subcategory_cat.apply(lambda x: x not in list(dict_resamble.keys()))]\n",
    "\n",
    "labels_ = labels[labels.subcategory_cat.apply(lambda x: x in list(dict_resamble.keys()))]\n",
    "labels = labels[labels.subcategory_cat.apply(lambda x: x not in list(dict_resamble.keys()))]\n",
    "\n",
    "ros = RandomOverSampler(random_state=0,sampling_strategy='all')\n",
    "df_, labels_ = ros.fit_resample(df_, labels_)\n",
    "\n",
    "\n",
    "df =pd.concat([df, df_])\n",
    "labels = pd.concat([labels, labels_])\n",
    "\n",
    "# DataFrame Final\n",
    "df.reset_index(drop=True,inplace= True)\n",
    "labels.reset_index(drop=True,inplace= True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Podemos ver los resultados de MLFlow si ejecutamos en la terminal:\n",
    "\n",
    "\n",
    "\n",
    " _mlflow ui -p 1234_\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Cargar modelos de origen https://huggingface.co/\n",
    "path = 'dccuchile/bert-base-spanish-wwm-uncased'\n",
    "name_model = 'dccuchile/bert-base-spanish-wwm-uncased'\n",
    "\n",
    "\n",
    "#model = SentenceTransformer('dccuchile/bert-base-spanish-wwm-cased') \n",
    "#model.save()\n",
    "\n",
    "# Sentences we want sentence embeddings for\n",
    "num_labels = labels['subcategory_cat'].nunique()\n",
    "\n",
    "# Load model from HuggingFace Hub\n",
    "tokenizer = AutoTokenizer.from_pretrained(name_model)\n",
    "model = AutoModel.from_pretrained(name_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Procesar Texto"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Generar el embbending  y las mascara para cada transacción\n",
    "\"\"\"\n",
    "\n",
    "token_id = []\n",
    "attention_masks = []\n",
    "\n",
    "for sample in df.clean_description.tolist():\n",
    "    encoding_dict = preprocessing(sample, tokenizer)\n",
    "    token_id.append(encoding_dict['input_ids']) \n",
    "    attention_masks.append(encoding_dict['attention_mask'])\n",
    "\n",
    "\n",
    "token_id = torch.cat(token_id, dim = 0)\n",
    "attention_masks = torch.cat(attention_masks, dim = 0)\n",
    "labels = torch.tensor(labels['subcategory_cat'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hiperparámetros"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# fix random seed for reproducibility\n",
    "# Recommended number of epochs: 2, 3, 4. See: https://arxiv.org/pdf/1810.04805.pdf\n",
    "# Recommended batch size: 16, 32. See: https://arxiv.org/pdf/1810.04805.pdf\n",
    "# define 10-fold cross validation test harness\n",
    "\n",
    "seed = 9\n",
    "random.seed(seed)\n",
    "num_folds = 10\n",
    "epochs = 4\n",
    "n_features = 2**8\n",
    "C = logspace(-3,3,7)\n",
    "\n",
    "threshold = 0.70\n",
    "\n",
    "kfold = StratifiedKFold(n_splits= num_folds, shuffle=True, random_state=seed)\n",
    "logs = []\n",
    "\n",
    "val_ratio = 0.2\n",
    "batch_size = 16\n",
    "\n",
    "# Indices of the train and validation splits stratified by labels\n",
    "# train_idx, val_idx = train_test_split(\n",
    "#    np.arange(len(labels)),\n",
    "#    test_size = val_ratio,\n",
    "#    shuffle = True,\n",
    "#    stratify = labels)\n",
    "\n",
    "def generate_split(train_idx,val_idx):\n",
    "    # Train and validation sets\n",
    "    train_set = TensorDataset(token_id[train_idx], \n",
    "                              attention_masks[train_idx], \n",
    "                              labels[train_idx])\n",
    "\n",
    "    val_set = TensorDataset(token_id[val_idx], \n",
    "                            attention_masks[val_idx], \n",
    "                            labels[val_idx])\n",
    "\n",
    "    # Prepare DataLoader\n",
    "    train_dataloader = DataLoader(\n",
    "                train_set,\n",
    "                sampler = RandomSampler(train_set),\n",
    "                batch_size = batch_size\n",
    "            )\n",
    "\n",
    "    validation_dataloader = DataLoader(\n",
    "                val_set,\n",
    "                sampler = SequentialSampler(val_set),\n",
    "                batch_size = batch_size\n",
    "            )\n",
    "    return train_dataloader,validation_dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## set dataset train "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y = labels.numpy()\n",
    "X = df.to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "name_experiment = get_timestamp()\n",
    "mlflow.set_experiment(name_experiment)\n",
    "\n",
    "# Auto log all MLflow entities\n",
    "mlflow.pytorch.autolog()\n",
    "with mlflow.start_run():\n",
    "\n",
    "    for num_fold, [train_idx, val_idx] in enumerate(kfold.split(X, Y)):\n",
    "        print(\"num_fold: \",num_fold)\n",
    "        \n",
    "\n",
    "        with mlflow.start_run(nested=True):\n",
    "           \n",
    "            labels = torch.tensor(Y)\n",
    "            train_dataloader,validation_dataloader = generate_split(train_idx,val_idx)\n",
    "            \n",
    "            # ------------------------------------------------------<load model>\n",
    "            # Load the BertForSequenceClassification model\n",
    "            model = BertForSequenceClassification.from_pretrained(\n",
    "                name_model,\n",
    "                num_labels = num_labels,\n",
    "                output_attentions = False,\n",
    "                output_hidden_states = False,\n",
    "            )\n",
    "\n",
    "            # Recommended learning rates (Adam): 5e-5, 3e-5, 2e-5. See: https://arxiv.org/pdf/1810.04805.pdf\n",
    "            optimizer = torch.optim.AdamW(model.parameters(), \n",
    "                                          lr = 5e-5,\n",
    "                                          eps = 1e-08\n",
    "                                          )\n",
    "            # Run on GPU\n",
    "            model.cuda()\n",
    "\n",
    "            mlflow.log_param(\"Fold\",num_fold)\n",
    "\n",
    "\n",
    "            #mlflow.log_param(\"n_estimators\",n_estimators)\n",
    "            #mlflow.log_param(\"random_state\",random_state)\n",
    "                        # Tracking variables \n",
    "            val_accuracy = []\n",
    "            val_precision = []\n",
    "            val_recall = []\n",
    "            val_f1 = []\n",
    "            cv_real = []\n",
    "            cv_pred = []\n",
    "            \n",
    "            for epoch in trange(epochs, desc = 'Epoch'):\n",
    "                print(\"Num epoch: \", epoch)\n",
    "                \n",
    "                with mlflow.start_run(nested=True):\n",
    "                    mlflow.log_param(\"Epoch\",epoch)\n",
    "\n",
    "                    # Tracking variables\n",
    "                    tr_loss = 0\n",
    "                    nb_tr_examples, nb_tr_steps = 0, 0\n",
    "\n",
    "                    # Set model to training mode\n",
    "                    model.train()\n",
    "                    # -------------------------------------------------------<loop batch>\n",
    "                    for step, batch in enumerate(train_dataloader):\n",
    "                        if step%20 == 0:\n",
    "                            print(\"step: \", step)\n",
    "\n",
    "                        batch = tuple(t.to(device) for t in batch)\n",
    "\n",
    "                        b_input_ids, b_input_mask, b_labels = batch\n",
    "\n",
    "\n",
    "                        #print(\"b_labels:\", b_labels)\n",
    "\n",
    "                        optimizer.zero_grad()\n",
    "                        #b_labels = torch.tensor(labels).unsqueeze(0)\n",
    "                        # torch.tensor(labels).float().to(device)\n",
    "                        b_labels = b_labels.type(torch.LongTensor)   # casting to long\n",
    "                        b_labels = b_labels.to(device)\n",
    "\n",
    "                        # --------------------------------------------------------<fit>\n",
    "                        # Forward pass\n",
    "                        train_output = model(b_input_ids, \n",
    "                                             token_type_ids = None, \n",
    "                                             attention_mask = b_input_mask, \n",
    "                                             labels = b_labels)\n",
    "\n",
    "\n",
    "\n",
    "                        # Backward pass\n",
    "                        # train_output.loss.backward()\n",
    "                        loss = F.cross_entropy( train_output.logits,b_labels)\n",
    "                        loss.backward()\n",
    "\n",
    "                        optimizer.step()\n",
    "                        # Update tracking variables\n",
    "                        tr_loss += train_output.loss.item()\n",
    "                        nb_tr_examples += b_input_ids.size(0)\n",
    "                        nb_tr_steps += 1\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "                    # ------------------------------------------------<evaluate>\n",
    "\n",
    "                    # Set model to evaluation mode\n",
    "                    model.eval()\n",
    "\n",
    "\n",
    "                    for batch in validation_dataloader:\n",
    "                        batch = tuple(t.to(device) for t in batch)\n",
    "                        b_input_ids, b_input_mask, b_labels = batch\n",
    "                        with torch.no_grad():\n",
    "                          # Forward pass\n",
    "                          eval_output = model(b_input_ids, \n",
    "                                              token_type_ids = None, \n",
    "                                              attention_mask = b_input_mask)\n",
    "                        #-------------------------------------------------<Metrcis>\n",
    "\n",
    "                        logits = eval_output.logits.detach().cpu().numpy()\n",
    "                        labels = b_labels.to('cpu').numpy()\n",
    "\n",
    "                        preds = np.argmax(logits, axis=-1)\n",
    "\n",
    "                        # Calculate validation metrics\n",
    "                        precision, recall, f1, _= precision_recall_fscore_support(labels, preds,  average='weighted', labels=np.unique(labels))\n",
    "                        acc =accuracy_score(labels, preds)\n",
    "\n",
    "                        val_accuracy.append(acc)\n",
    "                        val_precision.append(precision)\n",
    "                        val_recall.append(recall)\n",
    "                        val_f1.append(f1)\n",
    "\n",
    "                        cv_real.extend(labels)\n",
    "                        cv_pred.extend(preds)\n",
    "                        \n",
    "                    print(\"******************************************************<epoch>\")\n",
    "                    \n",
    "                    mlflow.log_param(\"loss\",tr_loss / nb_tr_steps)\n",
    "                    print('\\n\\t - Train loss: {:.4f}'.format(tr_loss / nb_tr_steps))\n",
    "                    print('\\t - Validation Accuracy: {:.4f}'.format(acc))\n",
    "                    print('\\t - Validation Precision: {:.4f}'.format(precision)) \n",
    "                    print('\\t - Validation Recall: {:.4f}'.format(recall) )\n",
    "                    print('\\t - Validation F1: {:.4f}\\n'.format(f1))\n",
    "                    print(\"******************************************************<fin de epoch>\")\n",
    "\n",
    "\n",
    "            # -----------------------------------------------------\n",
    "            print(\"-----------------------------------------------------------------------<fold>\")\n",
    "            \n",
    "            \n",
    "            components = {\n",
    "                \"model\": model,\n",
    "                \"tokenizer\": tokenizer,\n",
    "            }\n",
    "            mlflow.transformers.save_model(\n",
    "                transformers_model=components,\n",
    "                artifact_path=\"results\",\n",
    "                path = 'results/model/' + str(generate(size=40))\n",
    "            )\n",
    "                                \n",
    "                \n",
    "                \n",
    "            mlflow.pytorch.log_model(model, \"model_\"+ str(num_fold))\n",
    "\n",
    "            mlflow.log_param(\"acc\",sum(val_accuracy)/len(val_accuracy))\n",
    "            mlflow.log_param(\"precision\",sum(val_precision)/len(val_precision))\n",
    "            mlflow.log_param(\"Recall\",sum(val_recall)/len(val_recall))\n",
    "            mlflow.log_param(\"F1\",sum(val_f1)/len(val_f1))\n",
    "\n",
    "            # -----------------------------------------------------\n",
    "\n",
    "            cm = confusion_matrix(cv_real[:], cv_pred[:])\n",
    "            mlflow.log_param(\"cm\",cm)\n",
    "\n",
    "            print('\\t - Validation Accuracy: {:.4f}'.format(sum(val_accuracy)/len(val_accuracy)))\n",
    "            print('\\t - Validation Precision: {:.4f}'.format(sum(val_precision)/len(val_precision)) if len(val_precision)>0 else '\\t - Validation Precision: NaN')\n",
    "            print('\\t - Validation Recall: {:.4f}'.format(sum(val_recall)/len(val_recall)) if len(val_recall)>0 else '\\t - Validation Recall: NaN')\n",
    "            print('\\t - Validation F!: {:.4f}\\n'.format(sum(val_f1)/len(val_f1)) if len(val_f1)>0 else '\\t - Validation F1: NaN')\n",
    "            model.save_pretrained(\"results/\"+name_experiment+'_' + str(num_fold))\n",
    "            print(\"-----------------------------------------------------------------------<fin de fold>\\n\\n\")\n",
    "\n",
    "mlflow.end_run()\n",
    "\n",
    "\n",
    "\n",
    "file_name = \"results/\"+name_experiment\n",
    "key='beto/index/'\n",
    "uploadDirectory(path=file_name,key =key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import shutil\n",
    "shutil.make_archive('ehkHjWs5RE7YOwv2eDTEq-GVki6T00f18hekL2Ht', 'zip', 'results/model/ehkHjWs5RE7YOwv2eDTEq-GVki6T00f18hekL2Ht')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shutil.make_archive('model_bert_spamish_fine_tuning_2023-05-25-15-43_5', 'zip', 'results/model_bert_spamish_fine_tuning_2023-05-25-15-43_5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "!ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_sentence = 'retiro de cajero automático'\n",
    "new_sentence = 'oxxo'\n",
    "\n",
    "# We need Token IDs and Attention Mask for inference on the new sentence\n",
    "test_ids = []\n",
    "test_attention_mask = []\n",
    "\n",
    "# Apply the tokenizer\n",
    "encoding = preprocessing(new_sentence, tokenizer)\n",
    "\n",
    "# Extract IDs and Attention Mask\n",
    "test_ids.append(encoding['input_ids'])\n",
    "test_attention_mask.append(encoding['attention_mask'])\n",
    "test_ids = torch.cat(test_ids, dim = 0)\n",
    "test_attention_mask = torch.cat(test_attention_mask, dim = 0)\n",
    "\n",
    "# Forward pass, calculate logit predictions\n",
    "with torch.no_grad():\n",
    "    output = model(test_ids.to(device), token_type_ids = None, attention_mask = test_attention_mask.to(device))\n",
    "\n",
    "\n",
    "np.argmax(output.logits.cpu().numpy())\n",
    "\n",
    "print('Input Sentence: ', new_sentence)\n",
    "print('Predicted Class: ',dict_cats[np.argmax(output.logits.cpu().numpy())])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plot_confusion_matrix(conf_mat=cm,\n",
    "                                colorbar=True,\n",
    "                                show_absolute=False,\n",
    "                                show_normed=True,\n",
    "                                class_names=labes_names,\n",
    "                               figsize=(30, 30))\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.metrics import plot_confusion_matrix\n",
    "# plot_confusion_matrix(clf,X_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df_class_report = pd.DataFrame(classification_report(cv_real[:], cv_pred[:],output_dict=True)).transpose()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_class_report[df_class_report['precision']>.60].index"
   ]
  }
 ],
 "metadata": {
  "availableInstances": [
   {
    "_defaultOrder": 0,
    "_isFastLaunch": true,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 4,
    "name": "ml.t3.medium",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 1,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.t3.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 2,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.t3.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 3,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.t3.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 4,
    "_isFastLaunch": true,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.m5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 5,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.m5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 6,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.m5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 7,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.m5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 8,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.m5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 9,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.m5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 10,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.m5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 11,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.m5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 12,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.m5d.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 13,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.m5d.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 14,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.m5d.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 15,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.m5d.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 16,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.m5d.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 17,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.m5d.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 18,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.m5d.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 19,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.m5d.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 20,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": true,
    "memoryGiB": 0,
    "name": "ml.geospatial.interactive",
    "supportedImageNames": [
     "sagemaker-geospatial-v1-0"
    ],
    "vcpuNum": 0
   },
   {
    "_defaultOrder": 21,
    "_isFastLaunch": true,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 4,
    "name": "ml.c5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 22,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.c5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 23,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.c5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 24,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.c5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 25,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 72,
    "name": "ml.c5.9xlarge",
    "vcpuNum": 36
   },
   {
    "_defaultOrder": 26,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 96,
    "name": "ml.c5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 27,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 144,
    "name": "ml.c5.18xlarge",
    "vcpuNum": 72
   },
   {
    "_defaultOrder": 28,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.c5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 29,
    "_isFastLaunch": true,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.g4dn.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 30,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.g4dn.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 31,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.g4dn.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 32,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.g4dn.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 33,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.g4dn.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 34,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.g4dn.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 35,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 61,
    "name": "ml.p3.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 36,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 244,
    "name": "ml.p3.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 37,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 488,
    "name": "ml.p3.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 38,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.p3dn.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 39,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.r5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 40,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.r5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 41,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.r5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 42,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.r5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 43,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.r5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 44,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.r5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 45,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 512,
    "name": "ml.r5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 46,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.r5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 47,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.g5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 48,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.g5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 49,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.g5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 50,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.g5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 51,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.g5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 52,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.g5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 53,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.g5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 54,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.g5.48xlarge",
    "vcpuNum": 192
   },
   {
    "_defaultOrder": 55,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 1152,
    "name": "ml.p4d.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 56,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 1152,
    "name": "ml.p4de.24xlarge",
    "vcpuNum": 96
   }
  ],
  "instance_type": "ml.m5.large",
  "kernelspec": {
   "display_name": "Python 3 (Data Science)",
   "language": "python",
   "name": "python3__SAGEMAKER_INTERNAL__arn:aws:sagemaker:us-west-2:236514542706:image/datascience-1.0"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
