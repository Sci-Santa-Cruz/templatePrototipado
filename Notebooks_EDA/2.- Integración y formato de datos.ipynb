{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "<div class=\"jumbotron\">\n",
    "  <h1><i class=\"fa fa-bar-chart\" aria-hidden=\"true\"></i> Integracción y limpieza</h1>\n",
    "  <p></p>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Objetivo\n",
    "\n",
    "Integrar todas las fuentes de datos en un único archivo con formato PICKLE, el cual será utilizado en los pasos de análisis. El archivo se almacena en el folder `data/interim/`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pandas import read_csv,set_option,Series\n",
    "import  pickle\n",
    "import numpy as np\n",
    "import glob\n",
    "import os\n",
    "import json\n",
    "import urllib.request\n",
    "from os import path\n",
    "#from dotenv import load_dotenv, find_dotenv\n",
    "\n",
    "os.chdir(\"..\")\n",
    "set_option('display.width', 1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Obtención de los datos "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Download"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Caso 1: Las fuentes de datos son urls con la misma estrutura.\n",
    "\n",
    "Descargar datos a `data/raw/`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Lista de URLs a descargar\n",
    "urls = ['url1', 'url2', 'url3']\n",
    "\n",
    "# Iterar a través de las URLs y descargar los archivos\n",
    "for url in urls:\n",
    "    # Extraer el nombre del archivo de la URL dividiendo la URL por las barras diagonales y tomando el último elemento\n",
    "    filename = url.split('/')[-1]\n",
    "\n",
    "    # Crear la ruta completa donde se almacenará el archivo descargado, en este caso dentro del directorio 'data/raw/'\n",
    "    path_file = 'data/raw/' + filename\n",
    "\n",
    "    # Verificar si el archivo ya existe en la ubicación especificada\n",
    "    if not path.exists(path_file):\n",
    "        # Si el archivo no existe, descargarlo desde la URL y guardar en la ruta especificada\n",
    "        urllib.request.urlretrieve(url, path_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cargar datos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Leer todos los archivos que fueron descargados a `data/raw/`. Todos deben de contener la misma estructura"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "path = os.getcwd()\n",
    "all_files = glob.glob(os.path.join(path , \"../data/raw/*.*\"))\n",
    "\n",
    "#lista de dataframes\n",
    "li = []\n",
    "\n",
    "for filename in all_files:\n",
    "    df = read_csv(filename, index_col=None, header=0)\n",
    "    \n",
    "    li.append(df)\n",
    "\n",
    "# df = pd.concat(li, axis=0, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!ls"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Carga individual"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Caso 2 : Archivos indivuduales"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Leer archivo o archivos "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df = read_csv('data/raw/file.csv') "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Unir diversos DataFrames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pd.merge(df_1, df_2, on=['country', 'year'], how='left')\n",
    "# pd.merge(df_movie, df_gender[df_gender.gen_title=='Drama'], how='inner',left_on='genero', right_on='gen_id')\n",
    "# pd.merge(productos_df, modelo_df, on='ID_Marca', how='inner')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Descripción "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fuentes y diccionario de datos\n",
    "\n",
    "### Sobre los datos\n",
    "    agregar descripción de las fuentes de datos\n",
    "\n",
    "### Diccionario de datos\n",
    "        agregar diccionario \n",
    "\n",
    "### ¿Qué transformaciones ha sufrido el archivo?\n",
    "    agregar linaje de datos \n",
    "\"\"\"\n",
    "h=0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mostrar los 5 primeros renglones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mostart las dimensiones del `Dataframe` "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-info\" role=\"alert\">\n",
    "<ul>\n",
    "<li> agregar insights ... </ul>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Nombre de las columnas "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list(df.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cambiar el nombre de las variables\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# columns = []\n",
    "# df.columns = columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tipo de datos detectados por Pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dar formato de datetime a las variables de tiempo y fechas "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Catch string to datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Formatos de fecha comunes\n",
    "format= '%Y-%m-%d %H:%M:%S'\n",
    "format_alternativo = '%m/%d/%Y %H:%M:%S'\n",
    "    \n",
    "# df['datetime'] = pd.to_datetime(df[''],format=formato)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Filtro para conversión"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df[''] = df[''].str.replace('\\..*', '')\n",
    "# df[''] = df[''].apply(lambda x: len(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extraer periodo de tiempo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df['periodo'] = df.__.apply(lambda x: x.strftime('%Y-%m'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extracción de partes de la fecha"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_movie['year']=df_movie[''].dt.year\n",
    "# df_movie['month']=df_movie[''].dt.month\n",
    "# df_movie['day']=df_movie[''].dt.day"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Estandarizar fecha"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from utils.custom import datetime_convert\n",
    "\n",
    "# format = '%Y-%m-%d %H:%M:%S'\n",
    "# df.column.apply(lambda x: datetime_convert(x,output_format= format))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Valores nulos o faltantes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Valores nulos como porcentaje "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "((df.isnull().sum() / len(df))*100).sort_values(ascending = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-info\" role=\"alert\">\n",
    "<ul>\n",
    "<li> En términos generales, se suelen considerar los siguientes grados de impacto, dependiendo del porcentaje de valores faltantes (dumb rules):\n",
    "\n",
    "- Menos de 1%: Trivial (no relevante)\n",
    "- 1-5%: Manejable\n",
    "- 5-15%: Manejable mediante métodos sofisticados\n",
    "- Más de 15%: Crítico, con impacto severo en cualquier tipo de interpretación\n",
    " \n",
    "    \n",
    "Debido a que la mayoría de la variables contiene datos ausentes con un porcentaje inferior al 1% se procederá a remover dichas muestras. La variables 'Genero_Usuario' al no rebasar el 5% de datos ausentes puede continuar dentro de las variables de análisis sin un mayor impacto que remover la muetras que contienen valores nulos.\n",
    "    \n",
    "<li> Nota: Por falta de tiempo no se lidia con los datos faltantes de la variable Genero_Usuario. En un entorno productivo si la varible sobre pasa en 1% se debe utilizar tecnicas de inputación de datos para reducir el porcentaje de valores nullos.\n",
    "    \n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analisis de valores faltantes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-warning\"><b>Atención: </b>\n",
    "Esta plantilla sobre cubre el caso base, en el cual,  el porcentaje de valores faltantes es trivial y se eliminan.\n",
    "Los casos restantes de técnicas de imputaciñon se cubren el el Notebook de referente a trasnformación de datos.\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Inputación de valores faltantes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Se eliminan\n",
    "df.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Número de muestras eliminados\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Valores duplicados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remover los datos duplicados\n",
    "df.drop_duplicates(keep='first',inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Núm. de registros eliminados"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Verificar datos "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Datos nulos\n",
    "((df.isnull().sum() / len(df))*100).sort_values(ascending = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Obtener el nombre de las variables categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#NA\n",
    "#categorical = ['variety']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Almacenar el diccionario de clases "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Este diccionario se utilizan en la etapa de predicción"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save category dict\n",
    "# dict_cat_to_code = Series(df['variety'].unique()).to_dict()\n",
    "\n",
    "# with open(\"data/interim/dict_cat_to_code.json\", \"w\") as outfile:\n",
    "#    json.dump(dict_cat_to_code, outfile)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convertir las variables a tipo `category`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for name in categorical :\n",
    "# df['column_name']= df['column_name'].astype(\"category\")\n",
    "# df['class']= df['variety'].astype(\"category\").cat.codes.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Almacenar el `dataframe` en formato pickle "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Store data en formar pickle\n",
    "with open('data/interim/format.pickle', 'wb') as handle:\n",
    "    pickle.dump(df, handle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
